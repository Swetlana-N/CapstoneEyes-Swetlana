{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 15,
   "id": "67e906f1",
=======
   "execution_count": 2,
   "id": "87df76f7",
>>>>>>> Stashed changes
   "metadata": {
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1646270525010,
     "user": {
      "displayName": "Harry Le",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7i4_XqzkM7KujMmQfRXPeQfvMUEkaIw06fLqslQ=s64",
      "userId": "06537148089668787274"
     },
     "user_tz": -660
    },
    "id": "67e906f1"
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
<<<<<<< Updated upstream
    "from scipy.spatial import distance as dist\n",
=======
    "# 1. SQL Integration\n",
    "#import mysql.connector\n",
    "#from mysql.connector import errorcode\n",
    "# 2. Computer Vision\n",
>>>>>>> Stashed changes
    "from imutils.video import FileVideoStream\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
<<<<<<< Updated upstream
    "import dlib\n",
    "import cv2"
=======
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb74c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mydb = mysql.connector.connect(\n",
    "#    host = \"localhost\",\n",
    "#    user = \"root\",\n",
    "#    password = \"___\",\n",
    "#    database = 'capstone'\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb44363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0023fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e027571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cursor.execute('CREATE TABLE brLog(timestamp float, blink_count int, blink_rate float, primary key(timestamp))')"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 16,
   "id": "9409b6b5",
=======
   "execution_count": 7,
   "id": "bebd3e78",
>>>>>>> Stashed changes
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1646270525324,
     "user": {
      "displayName": "Harry Le",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7i4_XqzkM7KujMmQfRXPeQfvMUEkaIw06fLqslQ=s64",
      "userId": "06537148089668787274"
     },
     "user_tz": -660
    },
    "id": "9409b6b5"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 17,
   "id": "477108d0",
=======
   "execution_count": 8,
   "id": "65cb31a7",
>>>>>>> Stashed changes
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1646270525722,
     "user": {
      "displayName": "Harry Le",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7i4_XqzkM7KujMmQfRXPeQfvMUEkaIw06fLqslQ=s64",
      "userId": "06537148089668787274"
     },
     "user_tz": -660
    },
    "id": "477108d0"
   },
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
    "hog_face_detector = dlib.get_frontal_face_detector()"
=======
    "dlib_facelandmark = dlib.shape_predictor(\"D:/School/SEM 6/CAPSTONE/CapstoneEyes/shape_predictor_68_face_landmarks.dat\")"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 18,
   "id": "d3b439b7",
=======
   "execution_count": 9,
   "id": "459e302a",
>>>>>>> Stashed changes
   "metadata": {
    "executionInfo": {
     "elapsed": 1090,
     "status": "ok",
     "timestamp": 1646270529075,
     "user": {
      "displayName": "Harry Le",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7i4_XqzkM7KujMmQfRXPeQfvMUEkaIw06fLqslQ=s64",
      "userId": "06537148089668787274"
     },
     "user_tz": -660
    },
    "id": "d3b439b7"
   },
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
    "dlib_facelandmark = dlib.shape_predictor(\"D:/Study/Uni/1. Capstone II/PyCharm Codes/shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b87a7bec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1646270529076,
     "user": {
      "displayName": "Harry Le",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7i4_XqzkM7KujMmQfRXPeQfvMUEkaIw06fLqslQ=s64",
      "userId": "06537148089668787274"
     },
     "user_tz": -660
    },
    "id": "b87a7bec",
    "outputId": "dd59b300-f464-4715-ff0d-9d70ef689e44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwhile True:\\n    _, frame = cap.read()\\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\\n\\n    faces = hog_face_detector(gray)\\n    for face in faces:\\n\\n        face_landmarks = dlib_facelandmark(gray, face)\\n\\n        for n in range(0, 68):\\n            x = face_landmarks.part(n).x\\n            y = face_landmarks.part(n).y\\n            cv2.circle(frame, (x, y), 1, (0, 255, 255), 1)\\n\\n\\n    cv2.imshow(\"Face Landmarks\", frame)\\n\\n    key = cv2.waitKey(1)\\n    if key == 27:\\n        break\\ncap.release()\\ncv2.destroyAllWindows()\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test code for facial detection\n",
    "\"\"\"\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = hog_face_detector(gray)\n",
    "    for face in faces:\n",
    "\n",
    "        face_landmarks = dlib_facelandmark(gray, face)\n",
    "\n",
    "        for n in range(0, 68):\n",
    "            x = face_landmarks.part(n).x\n",
    "            y = face_landmarks.part(n).y\n",
    "            cv2.circle(frame, (x, y), 1, (0, 255, 255), 1)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Face Landmarks\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdbfaf2d",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1646270529076,
     "user": {
      "displayName": "Harry Le",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7i4_XqzkM7KujMmQfRXPeQfvMUEkaIw06fLqslQ=s64",
      "userId": "06537148089668787274"
     },
     "user_tz": -660
    },
    "id": "fdbfaf2d"
   },
   "outputs": [],
   "source": [
=======
>>>>>>> Stashed changes
    "def eye_aspect_ratio(eye):\n",
    "\t# compute the euclidean distances between the two sets of\n",
    "\t# vertical eye landmarks (x, y)-coordinates\n",
    "\tA = dist.euclidean(eye[1], eye[5])\n",
    "\tB = dist.euclidean(eye[2], eye[4])\n",
    "\n",
    "\t# compute the euclidean distance between the horizontal\n",
    "\t# eye landmark (x, y)-coordinates\n",
    "\tC = dist.euclidean(eye[0], eye[3])\n",
    "\n",
    "\t# compute the eye aspect ratio\n",
    "\tear = (A + B) / (2.0 * C)\n",
    "\n",
    "\t# return the eye aspect ratio\n",
    "\treturn ear"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 21,
   "id": "778bff48",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1646270529077,
     "user": {
      "displayName": "Harry Le",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7i4_XqzkM7KujMmQfRXPeQfvMUEkaIw06fLqslQ=s64",
      "userId": "06537148089668787274"
     },
     "user_tz": -660
    },
    "id": "778bff48"
   },
=======
   "execution_count": 10,
   "id": "a3f6f331",
   "metadata": {},
>>>>>>> Stashed changes
   "outputs": [],
   "source": [
    "def mouth_aspect_ratio(mouth): #internal lips\n",
    "    \n",
    "    #since the distance of 2 outer coordinates in terms of width of the mouth changes when there are actions\n",
    "    #cannot use the ratio of height/ width\n",
    "    #use the changes in average distance between coordiantes of inner lips\n",
    "    A = dist.euclidean(mouth[13], mouth[19])\n",
    "    B = dist.euclidean(mouth[14], mouth[18])\n",
    "    C = dist.euclidean(mouth[15], mouth[17])\n",
    "    \n",
    "    mar = (A + B + C) / 3.0\n",
    "    return mar"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 22,
   "id": "88332acf",
=======
   "execution_count": 11,
   "id": "a7939bd7",
>>>>>>> Stashed changes
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1646270529076,
     "user": {
      "displayName": "Harry Le",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7i4_XqzkM7KujMmQfRXPeQfvMUEkaIw06fLqslQ=s64",
      "userId": "06537148089668787274"
     },
     "user_tz": -660
    },
    "id": "b87a7bec",
    "outputId": "dd59b300-f464-4715-ff0d-9d70ef689e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 48\n"
     ]
    }
   ],
   "source": [
    "# grab the indexes of the facial landmarks for the left and\n",
    "# right eye, respectively\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "print(lStart, lEnd)\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 23,
   "id": "bd3f8bbd",
=======
   "execution_count": 15,
   "id": "1e3f4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "# print(mStart, mEnd) #(48,68)\n",
    "#there are 20 coordinates shaping the mouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed9047b5",
>>>>>>> Stashed changes
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1646270529076,
     "user": {
      "displayName": "Harry Le",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7i4_XqzkM7KujMmQfRXPeQfvMUEkaIw06fLqslQ=s64",
      "userId": "06537148089668787274"
     },
     "user_tz": -660
    },
    "id": "fdbfaf2d"
   },
   "outputs": [],
   "source": [
    "# start video capture\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# define two constants, \n",
    "# 1. the EAR threshold that the eye needs to pass (be lower than) in order to indicate a blink\n",
    "# 2. number of frames the eyes have to be in while having EAR lower than the detection threshold\n",
    "EYE_AR_THRESH = 0.25\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "\n",
    "#visualize EAR and MAR overtime to chooose the better value\n",
    "MAR_THRESHOLD = 14 #hyperparameter, need experiment\n",
    "MOUTH_CONSEC_FRAMES = 90\n",
    "#upper bound for mouth consec frames is 150\n",
    "\n",
    "# eyes-closed frame counter & total number of blinks while the code is running\n",
    "COUNTER = 0\n",
    "TOTAL = 0\n",
    "\n",
    "# create timer, with tick = frequency of capturing data into database\n",
    "start_time = time.time()\n",
<<<<<<< Updated upstream
=======
    "tick = 2\n",
    "\n",
    "# notification switch\n",
    "notisw = True\n",
    "\n",
    "# eye-strain & drowsiness notification variables\n",
    "strnotif = ''\n",
    "drwnotif = ''\n",
    "\n",
    "#20-20-20 notification variable & flag\n",
    "restnotif = ''\n",
    "restFlag = False\n",
    "\n",
    "#strain duration (counted by frames)\n",
    "strain_cnt = 0\n",
    "\n",
    "# initialize blinkrate variable & drowsiness flag\n",
    "#      (differentiate between eye strain and just having some shut eye for relaxation)\n",
    "blink_rate = 0\n",
    "drowsy_flag = False\n",
    "yawning = 0\n",
    "\n",
>>>>>>> Stashed changes
    "while True:\n",
    "    current_time = time.time()\n",
    "    duration = current_time - start_time\n",
    "    _, frame = cap.read()\n",
<<<<<<< Updated upstream
=======
    "    \n",
    "    #convert video capture to grayscale for detection model to work\n",
>>>>>>> Stashed changes
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    \n",
    "\n",
    "    faces = hog_face_detector(gray)\n",
    "    for face in faces:\n",
    "        # conversion to NumPy array to work with\n",
    "        face_landmarks = face_utils.shape_to_np(dlib_facelandmark(gray, face))\n",
    "\n",
    "        leftEye = face_landmarks[lStart:lEnd]\n",
    "        rightEye = face_landmarks[rStart:rEnd]\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    "        \n",
    "        \n",
    "        # average the eye aspect ratio together for both eyes\n",
    "        ear = (leftEAR + rightEAR) / 2\n",
    "        \n",
    "        # calculate the convex hull for each eye & visualization for detection of each \n",
    "        leftEyeHull = cv2.convexHull(leftEye)\n",
    "        rightEyeHull = cv2.convexHull(rightEye)\n",
    "        mouthHull = cv2.convexHull(mouth)\n",
    "        \n",
    "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "        cv2.drawContours(frame, [mouth], -1, (0, 255, 0), 1)\n",
    "        \n",
    "        # check to see if the eye aspect ratio is below the blink threshold\n",
    "        # if yes -> increment the blink frame counter\n",
    "        if ear < EYE_AR_THRESH:\n",
    "            COUNTER += 1\n",
    "        else:\n",
    "            # if the eyes were closed for a sufficient # of frames -> increment the total number of blinks\n",
    "            if COUNTER >= EYE_AR_CONSEC_FRAMES and COUNTER < 120:\n",
    "                TOTAL += 1\n",
    "                # reset the eyes-closed frame counter\n",
    "                COUNTER = 0\n",
    "            elif COUNTER >= 12: #if eyes are closed for longer or equal to 12 frames (roughly 400ms), then it counts as drowsy\n",
    "                drowsy_flag = True\n",
    "                \n",
    "            # reset the eyes-closed frame counter\n",
    "            # COUNTER = 0\n",
    "        \n",
    "        \n",
    "        #YAWNING DETECTION\n",
    "        mouth = face_landmarks[mStart:mEnd]\n",
    "        mar = mouth_aspect_ratio(mouth)\n",
    "        \n",
    "        #check if mar > threshold -> yawning\n",
    "        if mar > MAR_THRESHOLD:\n",
    "            yawning += 1\n",
    "            cv2.drawContours(frame, [mouth], -1, (0, 0, 255), 1) \n",
    "            #cv2.putText(frame, \"DROWSINESS ALERT!\", (270, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        \n",
    "        \n",
    "        # blink rate calculation\n",
    "        if duration != float(0):\n",
    "            blink_rate = 60*TOTAL/duration\n",
    "        \n",
<<<<<<< Updated upstream
=======
    "        br = int(blink_rate)\n",
    "        \n",
    "        \n",
    "        # notification system (on-frame)\n",
    "        if notisw == True:\n",
    "            if br > 20:\n",
    "                strnotif = 'Your eye is straining'\n",
    "            elif br > 15 and br <= 20:\n",
    "                strnotif = 'Normal blink rate'\n",
    "            elif br > 12 and br <= 15:\n",
    "                strnotif = 'Computer blink rate'\n",
    "                strain_cnt += 1\n",
    "\n",
    "            #if the eye suffers lower bilnk rate due to computer use for more than 5 minutes -> alert the user to go get some rest\n",
    "            # 5 minutes = 300 seconds. Considering webcam video is captured at 30fps -> eyes need to strain for 9000 frames\n",
    "            if strain_cnt == 9000:\n",
    "                strnotif = 'Go get some rest'\n",
    "                notisw = False\n",
    "        \n",
    "        #drowsiness detection\n",
    "        if br <= 12 & drowsy_flag == True:\n",
    "            drwnotif = 'STOP AND GO TO SLEEP YOU SLEEPYHEAD'\n",
    "        if yawning != 0:\n",
    "            drwnotif = 'STOP AND GO TO SLEEP YOU SLEEPYHEAD'\n",
    "        \n",
    "        '''\n",
    "        if int(duration) == tick:\n",
    "            tick += 2\n",
    "            cursor.execute('insert into brLog values (%s,%s,%s)', (duration, TOTAL, blink_rate))            \n",
    "            mydb.commit()\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        # 20-20-20 rule enforcement\n",
    "        # after 20', a notification will show up alerting the user to take a rest\n",
    "        if int(duration) % 5 == 0 and int(duration) != 0 and restFlag == False:\n",
    "            restnotif = 'Take a rest for 20 seconds'\n",
    "            restFlag = True\n",
    "            \n",
    "        \n",
>>>>>>> Stashed changes
    "        # draw the total number of blinks on the frame along with\n",
    "        # the computed eye aspect ratio for the frame\n",
    "        cv2.putText(frame, f\"Blinks: {TOTAL}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, f\"EAR: {ear:.2f}\", (300, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, f\"Duration: {duration:.2f}\", (10, 55),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, f\"Blink rate: {blink_rate:.2f}\", (10, 80),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, strnotif, (50, 180),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, drwnotif, (50, 210),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "        cv2.putText(frame,restnotif, (50, 250),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Face Landmarks\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    # stop code altogether & clean up window frame by pressing 1\n",
    "    if key == 49:\n",
    "        break\n",
    "    # the user will need to confirm that they will take a rest under 20-20-20 rule by pressing 2\n",
    "    elif key == 50:\n",
    "        restnotif = ''\n",
    "        restFlag = False\n",
    "    # confirm eye strain rest by pressing 3\n",
    "    elif key == 51:\n",
    "        strain_cnt = 0\n",
    "        notisw =  True\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< Updated upstream
   "id": "9a73b685",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1646270529077,
     "user": {
      "displayName": "Harry Le",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7i4_XqzkM7KujMmQfRXPeQfvMUEkaIw06fLqslQ=s64",
      "userId": "06537148089668787274"
     },
     "user_tz": -660
    },
    "id": "9a73b685"
   },
=======
   "id": "15b7fc0f",
   "metadata": {},
>>>>>>> Stashed changes
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< Updated upstream
   "id": "05b4bdde",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1646270529077,
     "user": {
      "displayName": "Harry Le",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7i4_XqzkM7KujMmQfRXPeQfvMUEkaIw06fLqslQ=s64",
      "userId": "06537148089668787274"
     },
     "user_tz": -660
    },
    "id": "05b4bdde"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9531d4a9",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1646270529078,
     "user": {
      "displayName": "Harry Le",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7i4_XqzkM7KujMmQfRXPeQfvMUEkaIw06fLqslQ=s64",
      "userId": "06537148089668787274"
     },
     "user_tz": -660
    },
    "id": "9531d4a9"
   },
=======
   "id": "f05bfbae",
   "metadata": {},
>>>>>>> Stashed changes
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "FacialLandmarkTest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< Updated upstream
   "version": "3.8.12"
=======
   "version": "3.6.13"
>>>>>>> Stashed changes
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
